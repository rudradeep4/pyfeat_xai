{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b45d3e-b039-41f5-be5a-5ea8ca5cf9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tqdm\n",
    "import cleese_stim as cleese\n",
    "from cleese_stim.engines import FaceWarp\n",
    "from feat import Detector\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from imageio.v2 import imread\n",
    "import pingouin as pg\n",
    "import cv2\n",
    "from scipy.spatial import distance\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40539ef-62a6-49f6-9a3c-55c19af7afdf",
   "metadata": {},
   "source": [
    "# Generate randomized stimuli using CLEESE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cfd9f0-ccad-48a4-bb85-9deeddef2496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_file = \"./images/londonset_scaled/070.jpg\"\n",
    "config_file = \"./configs/mediapipe.toml\"\n",
    "\n",
    "deformed = cleese.generate_stimuli(FaceWarp, img_file, config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76c2d68-0bea-4ea8-bad7-ef3d8274b5a6",
   "metadata": {},
   "source": [
    "# Pair stimuli randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66e3bf2-3f80-4d2e-95f6-8f5d1c4316c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "STIM_DIR = './outputs/londonset_output/070'\n",
    "\n",
    "stimuli = glob.glob(STIM_DIR + '/*.jpg')\n",
    "stimuli.remove(STIM_DIR + os.sep + '070.jpg')\n",
    "np.random.shuffle(stimuli)\n",
    "\n",
    "# create random pairs of simuli by splitting list of stims in half and zipping them together\n",
    "trials = list(zip(stimuli[:int(len(stimuli)/2)], stimuli[int(len(stimuli)/2):]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb716c6-9353-41fc-a5b6-15f1c3c264b7",
   "metadata": {},
   "source": [
    "# Detect AUs in stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a9ce10-e1f3-4000-bbe5-bcbce038419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm returns a binary label for each AU\n",
    "# detector = Detector(au_model='svm')\n",
    "\n",
    "# xgb returns continuous-valued detection probabilities\n",
    "detector = Detector(au_model='xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7855ea-5d70-4234-8a25-1758ef60dd73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_dfs = []\n",
    "\n",
    "for trial in tqdm.tqdm(trials):\n",
    "    stim1 = trial[0]\n",
    "    stim2 = trial[1]\n",
    "    \n",
    "    stim1_au_data = detector.detect_image(stim1).aus\n",
    "    stim2_au_data = detector.detect_image(stim2).aus\n",
    "\n",
    "    stim1_dfm = pd.read_csv(stim1.replace('jpg', 'txt'), header=None, skiprows=1, names=['idx', 'posX', 'posY', 'defX', 'defY'])\n",
    "    stim2_dfm = pd.read_csv(stim2.replace('jpg', 'txt'), header=None, skiprows=1, names=['idx', 'posX', 'posY', 'defX', 'defY'])\n",
    "\n",
    "    for au in stim1_au_data.columns:\n",
    "        # get AU probability estimate\n",
    "        stim1_score = stim1_au_data[au].iloc[0]\n",
    "        stim2_score = stim2_au_data[au].iloc[0]\n",
    "\n",
    "        # the image with higher estimate is defined as the model's response \n",
    "        if stim1_score > stim2_score or stim1_score == stim2_score:\n",
    "            stim1_dfm['au'], stim1_dfm['stim_order'], stim1_dfm['stim'], stim1_dfm['score'], stim1_dfm['response'] = au, 0, stim1, stim1_score, True\n",
    "            stim2_dfm['au'], stim2_dfm['stim_order'], stim2_dfm['stim'], stim2_dfm['score'], stim2_dfm['response'] = au, 1, stim2, stim2_score, False \n",
    "        elif stim1_score < stim2_score: \n",
    "            stim1_dfm['au'], stim1_dfm['stim_order'], stim1_dfm['stim'], stim1_dfm['score'], stim1_dfm['response'] = au, 0, stim1, stim1_score, False\n",
    "            stim2_dfm['au'], stim2_dfm['stim_order'], stim2_dfm['stim'], stim2_dfm['score'], stim2_dfm['response'] = au, 1, stim2, stim2_score, True\n",
    "            \n",
    "        df_au = pd.concat([stim1_dfm, stim2_dfm])\n",
    "        all_dfs.append(df_au)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d494c02e-97e2-4432-aaac-a690eecf0272",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(all_dfs)\n",
    "df.to_csv('./outputs/londonset_output/070.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a6a32c-4405-47b8-8bae-051996beb41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0fc6fd-2a51-414a-95ee-17d98657b9fc",
   "metadata": {},
   "source": [
    "# Average dfms of all chosen stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346058d4-89f1-438b-aab2-c1774eaf6b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# landmark_locs = {\n",
    "#     'silhouette': [\n",
    "#         10,  338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288,\n",
    "#         397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136,\n",
    "#         172, 58,  132, 93,  234, 127, 162, 21,  54,  103, 67,  109\n",
    "#     ],\n",
    "    \n",
    "#     'lipsUpperOuter': [61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291],\n",
    "#     'lipsLowerOuter': [146, 91, 181, 84, 17, 314, 405, 321, 375, 291],\n",
    "#     'lipsUpperInner': [78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308],\n",
    "#     'lipsLowerInner': [78, 95, 88, 178, 87, 14, 317, 402, 318, 324, 308],\n",
    "\n",
    "#     'lips': [61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308, 78, 95, 88, 178, 87, 14, 317, 402, 318, 324, 308],\n",
    "    \n",
    "#     'rightEyeUpper0': [246, 161, 160, 159, 158, 157, 173],\n",
    "#     'rightEyeLower0': [33, 7, 163, 144, 145, 153, 154, 155, 133],\n",
    "#     'rightEyeUpper1': [247, 30, 29, 27, 28, 56, 190],\n",
    "#     'rightEyeLower1': [130, 25, 110, 24, 23, 22, 26, 112, 243],\n",
    "#     'rightEyeUpper2': [113, 225, 224, 223, 222, 221, 189],\n",
    "#     'rightEyeLower2': [226, 31, 228, 229, 230, 231, 232, 233, 244],\n",
    "#     'rightEyeLower3': [143, 111, 117, 118, 119, 120, 121, 128, 245],\n",
    "    \n",
    "#     'rightEyebrowUpper': [156, 70, 63, 105, 66, 107, 55, 193],\n",
    "#     'rightEyebrowLower': [35, 124, 46, 53, 52, 65],\n",
    "    \n",
    "#     'rightEyeIris': [473, 474, 475, 476, 477],\n",
    "    \n",
    "#     'leftEyeUpper0': [466, 388, 387, 386, 385, 384, 398],\n",
    "#     'leftEyeLower0': [263, 249, 390, 373, 374, 380, 381, 382, 362],\n",
    "#     'leftEyeUpper1': [467, 260, 259, 257, 258, 286, 414],\n",
    "#     'leftEyeLower1': [359, 255, 339, 254, 253, 252, 256, 341, 463],\n",
    "#     'leftEyeUpper2': [342, 445, 444, 443, 442, 441, 413],\n",
    "#     'leftEyeLower2': [446, 261, 448, 449, 450, 451, 452, 453, 464],\n",
    "#     'leftEyeLower3': [372, 340, 346, 347, 348, 349, 350, 357, 465],\n",
    "    \n",
    "#     'leftEyebrowUpper': [383, 300, 293, 334, 296, 336, 285, 417],\n",
    "#     'leftEyebrowLower': [265, 353, 276, 283, 282, 295],\n",
    "    \n",
    "#     'leftEyeIris': [468, 469, 470, 471, 472],\n",
    "    \n",
    "#     'midwayBetweenEyes': [168],\n",
    "    \n",
    "#     'noseTip': [1],\n",
    "#     'noseBottom': [2],\n",
    "#     'noseRightCorner': [98],\n",
    "#     'noseLeftCorner': [327],\n",
    "    \n",
    "#     'rightCheek': [205],\n",
    "#     'leftCheek': [425],\n",
    "\n",
    "#     'cheek': [205, 425]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97d98a5-c9ed-4cc2-bccf-67998e2ec10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_file = \"./images/londonset_scaled/001.jpg\"\n",
    "# config_file = \"./configs/mediapipe.toml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072eff96-3a5b-46d6-87b7-4dcc2232e11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AU = 'AU12'\n",
    "# only_significant_landmarks = False\n",
    "\n",
    "# df = pd.read_csv('./outputs/londonset_output/001.csv').reset_index(drop=True)\n",
    "\n",
    "# df_au = df.loc[df.au == AU]\n",
    "# df_au"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca4b872-da19-4657-b0c8-42596caeb352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_single_kernel(data_df, feature_id = 'feature', value_id = 'value', response_id = 'response'):\n",
    "#     feature_average = data_df.groupby([feature_id,response_id])[value_id].mean().reset_index()\n",
    "#     positives = feature_average.loc[feature_average[response_id] == True].reset_index()\n",
    "#     negatives = feature_average.loc[feature_average[response_id] == False].reset_index()\n",
    "#     kernels = pd.merge(positives, negatives, on=feature_id, suffixes=('_true','_false'))\n",
    "#     kernels['kernel_value'] = kernels['%s_true'%value_id] - kernels['%s_false'%value_id]\n",
    "#     kernels = kernels[[feature_id,'kernel_value']].set_index(feature_id)\n",
    "#     kernels.index.names = ['feature']\n",
    "    \n",
    "#     return kernels\n",
    "\n",
    "\n",
    "# def normalize_kernel(kernel):\n",
    "#     rms = np.sqrt((kernel.kernel_value**2).mean())\n",
    "#     normalized_kernel = kernel.copy()\n",
    "#     normalized_kernel['kernel_value'] = normalized_kernel['kernel_value'].apply(lambda x: x/rms)\n",
    "        \n",
    "#     return normalized_kernel\n",
    "\n",
    "\n",
    "# def compute_kernel(data, normalize=True):\n",
    "#     kernel_x = extract_single_kernel(\n",
    "#         data,\n",
    "#         feature_id = 'idx',\n",
    "#         value_id = 'defX',\n",
    "#         response_id = 'response'\n",
    "#     )   \n",
    "#     kernel_y = extract_single_kernel(\n",
    "#         data,\n",
    "#         feature_id = 'idx',\n",
    "#         value_id = 'defY',\n",
    "#         response_id = 'response'\n",
    "#     )\n",
    "\n",
    "#     if normalize:\n",
    "#         kernel_x = normalize_kernel(kernel_x)\n",
    "#         kernel_y = normalize_kernel(kernel_y)\n",
    "\n",
    "#     kernel = pd.DataFrame({\n",
    "#         'index': kernel_x.index,\n",
    "#         'posX': data.posX[:len(kernel_x.index)],\n",
    "#         'posY': data.posY[:len(kernel_x.index)],\n",
    "#         'defX': kernel_x.kernel_value.values,\n",
    "#         'defY': kernel_y.kernel_value.values\n",
    "#     }).reset_index(drop=True)\n",
    "    \n",
    "#     return kernel       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40495e5a-cc36-4aac-a661-f0e89c200de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_dfmxy(filename, kernel):\n",
    "#     # formatting for saving as dfmxy\n",
    "#     txt_rows = []\n",
    "#     for el in kernel.to_string(index=False, index_names=False).split('\\n'):\n",
    "#         txt_rows.append(\",\".join(el.split()))\n",
    "    \n",
    "#     # write to text file\n",
    "#     with open(filename, 'a') as f:\n",
    "#         for row in txt_rows:\n",
    "#             f.write(row+\"\\n\")\n",
    "\n",
    "\n",
    "# def show_transform(dfmxy_file, kernel, scale):\n",
    "#     kernel = kernel.copy()\n",
    "    \n",
    "#     # rescale\n",
    "#     kernel.defX = scale * kernel.defX\n",
    "#     kernel.defY = scale * kernel.defY\n",
    "#     kernel.set_index('index').to_csv(dfmxy_file, index_label = 'index', header=None)\n",
    "    \n",
    "#     dfmxy = FaceWarp.load_dfmxy(dfmxy_file)\n",
    "#     transformed = cleese.process_file(\n",
    "#                                         FaceWarp,\n",
    "#                                         img_file,\n",
    "#                                         config_file,\n",
    "#                                         dfmxy=dfmxy\n",
    "#                                     )\n",
    "#     original_img = Image.open(img_file)\n",
    "#     transformed_img = Image.fromarray(transformed)\n",
    "#     # diff_img = Image.fromarray(np.asarray(original_img) - transformed)\n",
    "#     transformed_img.save(dfmxy_file.replace('dfmxy', 'jpg'))\n",
    "    \n",
    "#     fig, axs = plt.subplots(ncols=2)\n",
    "#     axs[0].imshow(original_img)\n",
    "#     axs[1].imshow(transformed_img, zorder=0)\n",
    "#     # axs[2].imshow(diff_img, zorder=0)\n",
    "#     axs[0].axis('off')\n",
    "#     axs[1].axis('off')\n",
    "#     # axs[2].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88957460-d716-4bd9-987f-b118155bbe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if only_significant_landmarks:\n",
    "#     # test = df_au.groupby('idx').apply(lambda x: pd.Series({\n",
    "#     #     'ttest': pg.ttest(\n",
    "#     #         np.sqrt(np.square(x.loc[x.response==True].defX) + np.square(x.loc[x.response==True].defY)),\n",
    "#     #         np.sqrt(np.square(x.loc[x.response==False].defX) + np.square(x.loc[x.response==False].defY)),\n",
    "#     #         paired=True\n",
    "#     #     )['p-val'].iloc[0]\n",
    "#     # }), include_groups=False)\n",
    "#     # sig = test.loc[test.ttest < 0.05].reset_index()\n",
    "#     data = df_au.loc[df_au.idx.isin(monalisa.iloc[:, 0])]\n",
    "# else:\n",
    "#     data = df_au\n",
    "\n",
    "# kernel = compute_kernel(data, normalize=True)\n",
    "# save_dfmxy(f'./kernels/{os.path.splitext(os.path.basename(img_file))[0]}_{AU}.dfmxy', kernel)\n",
    "# show_transform(f'./kernels/{os.path.splitext(os.path.basename(img_file))[0]}_{AU}.dfmxy', kernel, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5303ec50-ffa8-4d39-aca9-19e82dd7bc59",
   "metadata": {},
   "source": [
    "#### Average (defX, defY) of all kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d53fe25-ec5c-4de8-acd9-13dacb67c424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monalisa = pd.read_csv('./monalisa.random.dfmxy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edc38c3-4f68-4580-9197-124c2aec350b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./kernels/001_AU12.dfmxy', header=None)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b29902-b1e1-4b7a-bc04-57a1f2e7fd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def average_kernels(au):\n",
    "#     kernels = []\n",
    "#     for f in glob.glob(f'./kernels/*_{au}.dfmxy'):\n",
    "#         df = pd.read_csv(f, header=None)\n",
    "#         kernels.append(df.to_numpy())\n",
    "\n",
    "#     avg = np.mean(kernels, axis=0)\n",
    "#     avg_kernel = pd.DataFrame({\n",
    "#         'index': avg[:, 0],\n",
    "#         'posX': avg[:, 1],\n",
    "#         'posY': avg[:, 2],\n",
    "#         'defX': avg[:, 3],\n",
    "#         'defY': avg[:, 4]\n",
    "#     })\n",
    "\n",
    "#     return avg_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18dc28e-ab5b-4643-8f73-5a07120149c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avgk = average_kernels('AU12')\n",
    "# avgk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3fedf1-a601-4248-ae3c-d0d907af6d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_file = \"./images/londonset/004.jpg\"\n",
    "# config_file = \"./configs/mediapipe.toml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1553e30-ac6c-42c9-83aa-01a3c3ed35d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_transform(f'./kernels/avgkernel_AU12.dfmxy', avgk, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d922ace-2cd0-42c4-b2d1-2db86b049881",
   "metadata": {},
   "source": [
    "# Extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6a4cf4-7aec-4717-9773-9c48f2d5f8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k1 = pd.read_csv('./AM04NES_AU12.dfmxy', header=None)\n",
    "# k1.columns = ['idx', 'posX', 'posY', 'defX', 'defY']\n",
    "\n",
    "# k2 = pd.read_csv('./AF01NES_AU12.dfmxy', header=None)\n",
    "# k2.columns = ['idx', 'posX', 'posY', 'defX', 'defY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9577e022-5797-4218-804c-cb050efe2cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# commons = list(set(k1['idx'].to_list()) & set(k2['idx'].to_list()))\n",
    "# k1 = k1.loc[k1['idx'].isin(commons)].reset_index(drop=True)\n",
    "# k2 = k2.loc[k2['idx'].isin(commons)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba64ba33-7766-43bd-b1e3-7ca2cc18066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = k1.merge(k2, how='left', on='idx', suffixes=(None, '_other'))\n",
    "# k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc7df5b-330c-48b7-b0a6-ea54485f8608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k['avgX'] = k.apply(lambda x: (x.defX + x.defX_other)/2, axis=1)\n",
    "# k['avgY'] = k.apply(lambda x: (x.defY + x.defY_other)/2, axis=1)\n",
    "# k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5599313-ada6-4cfb-8a28-712433539055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_alt1 = k[['idx', 'posX', 'posY', 'avgX', 'avgY']].rename(columns={'idx': 'index', 'avgX': 'defX', 'avgY': 'defY'})\n",
    "# k_alt2 = k[['idx', 'posX_other', 'posY_other', 'avgX', 'avgY']].rename(columns={'idx': 'index', 'posX_other': 'posX', 'posY_other': 'posY', 'avgX': 'defX', 'avgY': 'defY'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9308be20-ab83-4862-8ee9-a26d02941c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_transform('./test.dfmxy', k_alt1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde3a8bf-2248-426d-805f-7aab9de345db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in monalisa.iloc[:, 0]:\n",
    "#     for el in landmark_locs:\n",
    "#         if i in landmark_locs[el]:\n",
    "#             print(f'{i}: {el}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f583f94f-ed58-4242-ad5f-fe91119c4a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.read_csv('./images/londonset_scaled/london_faces_info.csv')\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203cbdad-b04a-43fa-a814-de19c5a2a820",
   "metadata": {},
   "outputs": [],
   "source": [
    "info.loc[info.face_eth != 'white'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04c34cc-35ba-4849-9ecb-79ad1516c4f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
