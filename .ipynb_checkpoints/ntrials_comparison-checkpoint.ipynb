{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9412885c-613c-4369-abc0-d13cd565fc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import os\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from imageio.v2 import imread\n",
    "import pingouin as pg\n",
    "import cleese_stim as cleese\n",
    "from cleese_stim.engines import FaceWarp\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6cbbdf-da61-4eec-8524-37785ec4f940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def significant_landmarks(data):\n",
    "#     test = data.groupby('idx').apply(lambda x: pd.Series({\n",
    "#         'defX_ttest': pg.ttest(x[x.response==True].defX, x[x.response==False].defX)['p-val'].iloc[0], \n",
    "#         'defY_ttest': pg.ttest(x[x.response==True].defY, x[x.response==False].defY)['p-val'].iloc[0]\n",
    "#     }), include_groups=False)\n",
    "#     sig = test.loc[(test.defX_ttest < 0.05) | (test.defY_ttest < 0.05)].reset_index()\n",
    "    \n",
    "#     return data.loc[data.idx.isin(sig.idx.to_list())]\n",
    "    \n",
    "\n",
    "def extract_single_kernel(data_df, feature_id = 'feature', value_id = 'value', response_id = 'response'):\n",
    "    feature_average = data_df.groupby([feature_id,response_id])[value_id].mean().reset_index()\n",
    "    positives = feature_average.loc[feature_average[response_id] == True].reset_index()\n",
    "    negatives = feature_average.loc[feature_average[response_id] == False].reset_index()\n",
    "    kernels = pd.merge(positives, negatives, on=feature_id, suffixes=('_true','_false'))\n",
    "    kernels['kernel_value'] = kernels['%s_true'%value_id] - kernels['%s_false'%value_id]\n",
    "    kernels = kernels[[feature_id,'kernel_value']].set_index(feature_id)\n",
    "    kernels.index.names = ['feature']\n",
    "    \n",
    "    return kernels\n",
    "\n",
    "\n",
    "def normalize_kernel(kernel):\n",
    "    rms = np.sqrt((kernel.kernel_value**2).mean())\n",
    "    normalized_kernel = kernel.copy()\n",
    "    normalized_kernel['kernel_value'] = normalized_kernel['kernel_value'].apply(lambda x: x/rms)\n",
    "        \n",
    "    return normalized_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a651720-e598-4583-b217-637bc9fbb7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kernel(data, normalize=True):\n",
    "    kernel_x = extract_single_kernel(\n",
    "        data,\n",
    "        feature_id = 'idx',\n",
    "        value_id = 'defX',\n",
    "        response_id = 'response'\n",
    "    )   \n",
    "    kernel_y = extract_single_kernel(\n",
    "        data,\n",
    "        feature_id = 'idx',\n",
    "        value_id = 'defY',\n",
    "        response_id = 'response'\n",
    "    )\n",
    "\n",
    "    if normalize:\n",
    "        kernel_x = normalize_kernel(kernel_x)\n",
    "        kernel_y = normalize_kernel(kernel_y)\n",
    "\n",
    "    kernel = pd.DataFrame({\n",
    "        'index': kernel_x.index,\n",
    "        'posX': data.posX[:len(kernel_x.index)],\n",
    "        'posY': data.posY[:len(kernel_x.index)],\n",
    "        'defX': kernel_x.kernel_value.values,\n",
    "        'defY': kernel_y.kernel_value.values\n",
    "    }).reset_index(drop=True)\n",
    "    \n",
    "    return kernel      \n",
    "\n",
    "\n",
    "def save_dfmxy(filename, kernel):\n",
    "    # formatting for saving as dfmxy\n",
    "    txt_rows = []\n",
    "    for el in kernel.to_string(index=False, index_names=False).split('\\n'):\n",
    "        txt_rows.append(\",\".join(el.split()))\n",
    "    \n",
    "    # write to text file\n",
    "    with open(filename, 'a') as f:\n",
    "        for row in txt_rows:\n",
    "            f.write(row+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430da473-1cf6-4488-8f65-2caee022782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformed_img(data1, data2, ntrials, au, scale):\n",
    "    kernel1 = compute_kernel(data1, normalize=True)\n",
    "    kernel2 = compute_kernel(data2, normalize=True)\n",
    "    # rescale\n",
    "    kernel1.defX = scale * kernel1.defX\n",
    "    kernel1.defY = scale * kernel1.defY\n",
    "    # norm_defs_1 = MinMaxScaler().fit_transform(kernel1.iloc[:, [3, 4]].to_numpy())\n",
    "    # kernel1['defX'] = norm_defs_1[:, 0]\n",
    "    # kernel1['defY'] = norm_defs_1[:, 1]\n",
    "    kernel1.set_index('index').to_csv(f'./outputs/2000/AM04NES_{au}.dfmxy', index_label = 'index', header=None)\n",
    "    \n",
    "    kernel2.defX = scale * kernel2.defX\n",
    "    kernel2.defY = scale * kernel2.defY\n",
    "    # norm_defs_2 = MinMaxScaler().fit_transform(kernel2.iloc[:, [3, 4]].to_numpy())\n",
    "    # kernel2['defX'] = norm_defs_2[:, 0]\n",
    "    # kernel2['defY'] = norm_defs_2[:, 1]\n",
    "    kernel2.set_index('index').to_csv(f'./outputs/{ntrials}/AM04NES_{au}.dfmxy', index_label = 'index', header=None)\n",
    "\n",
    "    dot_products = []\n",
    "    for i in range(len(kernel1)):\n",
    "        dot_products.append(\n",
    "            (np.dot([kernel1.iloc[i].defX, kernel1.iloc[i].defY], [kernel2.iloc[i].defX, kernel2.iloc[i].defY]) + 1) / 2\n",
    "        )\n",
    "        \n",
    "    return np.mean(dot_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35819b81-2d91-4672-b5b9-73cc7f03644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "au_list = ['AU12'] \n",
    "           #, 'AU14', 'AU15', 'AU17', 'AU23', 'AU24', 'AU25', 'AU26', 'AU28', 'AU43']\n",
    "ideal = pd.read_csv('./outputs/2000/df_M.csv')\n",
    "\n",
    "ntrials = []\n",
    "aus = []\n",
    "sim = []\n",
    "for n in tqdm.tqdm(np.arange(100, 1100, step=100)):\n",
    "    d = pd.read_csv(f'./outputs/{n}/df_M.csv')\n",
    "    for au in au_list:\n",
    "        # ideal_data = significant_landmarks(data=ideal.loc[ideal.au == au])\n",
    "        # au_data = significant_landmarks(data=d.loc[d.au == au])\n",
    "        # au_data = d.loc[(d.au==au) & (d.idx.isin(ideal_data.idx.to_list()))]\n",
    "        ideal_data = ideal.loc[ideal.au==au]\n",
    "        au_data = d.loc[d.au==au]\n",
    "        dot_prod = get_transformed_img(ideal_data, au_data, n, au, scale=1)\n",
    "        \n",
    "        ntrials.append(n)\n",
    "        aus.append(au)\n",
    "        sim.append(dot_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0387e57-a3ef-4939-a44c-36b60ef054e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'ntrials': ntrials, 'au': aus, 'diff': sim})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6205ddba-b776-4f89-ad07-74fdcfd34ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=df, y='diff', x='ntrials')\n",
    "plt.ylim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433d88ea-e4b5-4d2a-bd5c-57545528db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_transform(dfmxy_file, kernel, img_file, config_file, scale):\n",
    "    kernel = kernel.copy()\n",
    "    \n",
    "    # rescale\n",
    "    kernel.defX = scale * kernel.defX\n",
    "    kernel.defY = scale * kernel.defY\n",
    "    kernel.set_index('index').to_csv(dfmxy_file, index_label = 'index', header=None)\n",
    "    \n",
    "    dfmxy = FaceWarp.load_dfmxy(dfmxy_file)\n",
    "    transformed = cleese.process_file(\n",
    "                                        FaceWarp,\n",
    "                                        img_file,\n",
    "                                        config_file,\n",
    "                                        dfmxy=dfmxy\n",
    "                                    )\n",
    "    original_img = Image.open(img_file)\n",
    "    transformed_img = Image.fromarray(transformed)\n",
    "    # diff_img = Image.fromarray(np.asarray(original_img) - transformed)\n",
    "    transformed_img.save(dfmxy_file.replace('dfmxy', 'jpg'))\n",
    "    \n",
    "    fig, axs = plt.subplots(ncols=2)\n",
    "    axs[0].imshow(original_img)\n",
    "    axs[1].imshow(transformed_img, zorder=0)\n",
    "    # axs[2].imshow(diff_img, zorder=0)\n",
    "    axs[0].axis('off')\n",
    "    axs[1].axis('off')\n",
    "    # axs[2].axis('off')\n",
    "\n",
    "kernel = pd.read_csv('./outputs/500/AM04NES_AU12.dfmxy', header=None)\n",
    "kernel.columns = ['index', 'posX', 'posY', 'defX', 'defY']\n",
    "show_transform('./outputs/500/test.dfmxy', kernel, './images/AM04NES.jpg', './configs/mediapipe.toml', 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
